#Kubernetes Architecture

#Nodes

- worker machine where container machines are launched

#Cluster

- group of nodes

#Master

- An another node with kubernetes installed
- Monitoring other nodes

#Components

- API Server (front end for kubernetes)

- etcd (distributed key value store)

- kubelet (agent running on each node in cluster. Verifies if nodes are running as expected)

- Container Runtime (underlying software to run containers. Docker)

- Controller (responsible for orchestration. brings new containers in case of failure)

- Scheduler(distributing work across nodes)

#Master vs Worker Nodes

- Master has 

1. kube-apiserver
2. etcd
3. controller
4. scheduler

- Worker has

1. Kubelet
2. Container Runtime is needed to run containers. Present in worker nodes




#Pods

- to encapsulate containers
- single instance of an application
1:1 relationship with containers

#Multi-Container Pods

- a single POD can have multiple containers
- helper container can live along with application container
- all containers in a single pod share the network and storage
- but this is a rare use case
- mostly single container pods are used


#kubectl

- Kube Control used to deploy and manage application in kubernetes cluster

kubectl run nginx --image nginx

- creates a pod and then deploys an instance of nginx docker image from dockerhub
- kubernetes can be configured to pull docker images from public or private repo

#yaml files

4 top-level fields

1. apiVersion
2. kind
	- used to create
	1. Pod
	2. Service
	3. ReplicaSet
	4. Deployment
3. metadata
	labels
	- to identify the pod	
4. spec


#Controller

- processes that control kubernetes

1. Replication Controller

- help to run multiple instance of a single pod in kubernetes cluster
- if exisitng pod fails, it brings up
- high availability and scaling
- older technology

2. Replica Set

- newer technology to replace replication controller
- It can also manage pods created outside replica set using selector
- Selector is the major difference between RC and RS

#Template Definition in RS

- to provide metadata and container specs

#Labels and Selectors

- RS to monitor existing pods
- used to monitor pods

#Scaling

1. Update replicas to 6 and run kubectl replace command
2. run scale command

#Deployments

- a kubernetes objects which supports rolling updates

#Namespaces

1. default namespace 
2. kube-system kubernetes has a namespace called kubesystem to place its own pods, services etc to run the system
3. kube-public to keep the resources to be used by others

- namespaces can be used to separate dev and prod resources
- namespace can have security policy and quota

- resources inside a namespace can communicate by their name
- resources from one namespace must use the namespace of other resources to connect outside

eg : db-service.dev.svc.cluster.local

service-name.namespace.service.domain

#Resource Quota

- to limit resources in a namespace

-------------------------------------------------------------------------------------------------------------
#Configuration

#argument will be appended to docker command
ENTRYPOINT["sleep"] 

#default argument
CMD["5]

CMD sleep 5
CMD["sleep","5"]

#Docker to Kubernetes Mapping

ENTRYPOINT["sleep"] -> commands:["sleep2.0"]
CMD["5"] -> args: ["10"]

- command field in kubernetes pod file overwrites the ENTRYPOINT command in docker file
- args field in kubernetes pod file overwrites the CMD command in docker file

#Environment Variables

env property
- it is an array

env:
	- name:
	  value:

#3 ways to set env variables

1. Plain key/value
2. ConfigMaps
3. Secrets

#ConfigMaps

- to pass config data as key value pairs to pods
- stores data in plain text format

1. Create Config Map
2. Inject into Pod

containers:
	- envFrom:
		- configMapRef:
			name: web-app-config
			
#Secrets

- to store sensitive data
- create secret and inject into pod

containers:
	- envFrom:
		- secretRef:
			name: app-secret
			
#Docker Security

- containers and the hosts share the same kernel
- containers are isolated from hosts using namespace
- containers and hosts have their own namespaces
- all containers have their own namespace and can see its processes only

#users

- By default, docker runs with root users
- root user on container different from the root user of hosts

#run with a different user

docker run --user=1000 ubuntu sleep 3600

- we can also set the userid inside the docker file

- Processes run by the root user has the highest privileges

- Docker uses linux capabilities. It restricts the root user with limited capabilities

--cap-add option
--cap-drop option
--privileged flag

#Service Accounts

1. User Accounts
- for humans

2. Service Acccounts
- for machines

eg: Prometheus, Jenkins

- a token is generated and stored as a secret object
- can use this token as bearer token to make a rest call to kubernetes api

- if the services like jenkins, prometheus run inside the kubernetes cluster, then the tokens can be mounted inside the pod. It can be easily read by the application

- Each namespace has its own serviceaccount and it is automatically mounted

#Resource Requirements

- Scheduler decides which pod goes to which node
- Every node has Disk, Memory and CPU

#1. CPU

Resource request by a container - 0.5 CPU, 256M
CPU - min 0.1 cpu or 1 milli

#2. Memory

1 ki to 1 G

- Kubernetes throttles the CPU if it exceeds the limit
- But if the POD uses more memory than the limit, then the POD will be terminated

#Taints and Tolerations

- Node 
- Pod

- To set restrictions on what pods can be scheduled on a node
- No unwanted pods can be placed in a node

2 steps

1. Set the taint on a node so that no pods can go inside it
2. Set tolerations on a particular pod which can then go in to the tainted node

#Taint Effect
1. NoSchedule
2. PreferNoSchedule
3. NoExecute

- Taints and Tolerations cannot decide which pod goes to which node
- Scheduler does not schedule any pods in master nodes because master node has taint applied

#Node Selectors

- To place a pod in a particular node using lables
- but not useful for complex node selectors

#Node Affinity

- Pods to Nodes
- Provides us with advanced capabilities to place the pods in nodes

#Types

1. requiredDuringSchedulingIgnoredDuringExecution

- if a matching node does not exist, then the pod will not run

2. preferredDuringSchedulingIgnoredDuringExecution

- POD will be placed on any node if matching node is available

---------------------------------------------------------------------------------

#MultiContainer Pods

- Created and destroyed together
- Share same lifecycle, network and storage

1. Ambassador

- running a container which proxies the request from webapp to connect to db

2. Adapter

- convert logs to a common format and send to central log server

3. Sidecar

- deploying a logging agent with a webserver pod.

------------------------------------------------------------------------------------

#Readiness and Liveness Probes

POD lifecycle

1. Pending state
2. ContainerCreating
3. Running

POD Conditions
- can be seen in POD description

readinessProbe: /api/ready

only when the api is up, kubernetes sends traffic to the pod

#Liveness Probes

- to periodically check the health of the application in the container 

#Logging

- to view logs from the pods

#Monitoring

- Metrics Server
- Prometheus
- ELK
- DATADOG
- dynatrace

#Metrics Server

- Heapster is deprecated
- 1 metrics server per kubernetes cluster
- It is an in memory server and does not store historical data
- For historical we need advanced monitoring systems mentioned above 
- Every node has an agent called kubelet
- Kubelet also contains a sub component called cAdvisor
- cAdvisor exposes metrics from nodes to metrics server

------------------------------------------------------------------------------------

#Labels and Selectors

Labels
- to identify using properties

Selectors
- to filter using labels

- Kubernetes internally used labels and selectors to connect the objects together

#Annotations

- to record other details for informatory purpose

#Rolling Updates and Deployments

#Rollouts and Versioning

- a deployment creates rollout
- rollout creates revision

#Rollout Strategy

1. Recreate

- Takedown all existing pods and deploy new pods
- There will be downtime for the application

2. Rolling Update

- Default strategy
- All pods will be updated one by one
- No downtime

#Rollback

- Kubernetes automcatically creates a new replicaset and creates new pods inside that
- We can easily rollback the deployments from the old replicaset
- kubernetes stores old replicaset for rollback purpose

#Record

- to record the commands run and it appears in Change-Cause during rollout history command

#Jobs

- Short term tasks
- default behaviour of pods is to run forever
- restartt set to always. Hence container is recreated if it exits
- Job is used to create a set of tasks to complete a work
- Job tries to creates pods until successful completions are met

#Parallel Jobs

completions: 3
parallelism: 3

#CronJobs

- A job that can be scheduled

Schedule
minutes hour days months week
30 21 * * *

------------------------------------------------------------------------------------

#Services

- enable communication with components outside application or users
- services connect many layers of pods
- enables loose coupling between microservices
- eg : external datasource

#External communication

- Service is an object to listen to a port and forward the request to a pod on the port running a web application

#Types

1. Node Port service

- Service listens on the node and forwards request to a pod on the port
 
2. ClusterIP

- service creates a virtual ip inside cluster to enable communication between different servers

3. Load Balancer

- Provisions a load balancer in supported cloud providers
- used in front end tier


#1. Node Port service

#Target Port

- port in the pod where web server is running

#Port

- port in the service
- Service is like a virtual server and in the cluster service has its own ip called the 
cluster ip

#Nodeport

- port in the node
- this port is used to access the wbe server externally
range (30000 to 32767)

- if the service finds multiple pods of same labels, it distributes loads to all the pods
- if the pods run in multiple nodes, kubernetes makes it available in the same node ports across all nodes
- we dont need any additional configuration

#Algorithm:

Random 
SessionAffinity is enabled


#2. Cluster IP service

- default service type
- internal ip of pods will change dynamically
- service groups pods and provides a single endpoint
- each layer can be easily scalable


#Ingress

- helps users to access a single external url 
- the ingress routes the requests to different services based on the url path
- we can also implement ssl
- it is like a Layer 7 Application load balancer inside the kubernetes cluster
- it is a kubernetes object
- can be a node port or load balancer service type

#IngressController

- kubernetes will deploy a reverse proxy solution like nginx, haproxy or traefik
- It will map the traffic from port 80 to the kubernetes node port like 30080
- The set of rules to configure ingress is called ingress resources
- It does not come by default

#Image - nginx-ingress-controller

- a special build used by kubernetes

- we need a service to expose the ingress controller

#Steps to create Ingress Controller

1. Create a deployment of type nginx ingress controller
2. Create a service to expose it to outside world
3. Create a configMap to feed nginx config data
4. A service account to set right permissions for the objects

#Steps to create Ingress Resource

- set of rules and configs applied on ingress controller
- eg: route based on url or domain name

#Network Policy

- By default "All Allow" rule which allows any nodes and services to connect with each other in the cluster
- Another object in kubernetes namespace
- done using labels and selectors

Following solutions support network policies
1. Kube-router
2. Calico
3. Romana
4. Weave-net

Flannel is not supported

- no need a separate rule for the response from a pod once request is allowed


------------------------------------------------------------------------------------

#State Persistence

#Volumes

- Docker containers are meant to be transient in nature
- data is destroyed along with container
- Data from container can be persisted in volumes
- config for volume goes inside the pod definiton file

#Mount

- to load data from volume

#Volume Types

- we can use many volume types like AWS EBS, Azure Disk etc

#Persistent Volumes (pv)

- Centralized storage

#Persistent Volume Claim(PVC)

- admin configures PV
- users can choose from the pool using pvc
- to make storage available to the nodes
- we can use selectors and lables to bind to the specific volumes

1:1 relationship between pv and pvc

- a pv can be used by only 1 pvc
- pvc will be pending state until a new pv is available

- when a pvc is deleted, pv is retained by default

- a PVC can be added to the pod definition file
